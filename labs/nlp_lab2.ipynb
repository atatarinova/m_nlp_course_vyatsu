{"cells":[{"cell_type":"markdown","metadata":{"id":"RObpMk4tNe2s"},"source":["# Лабораторная работа 2. Классификация текстов на основе вхождения в документ словарных слов"]},{"cell_type":"markdown","metadata":{"id":"dPtFkBosNe22"},"source":["**Задание 1.** Загрузите в датафрейм новостной датасет `lenta_ru_news_filtered.csv`, собранный на базе корпуса `lenta.ru v1.0`. В датасете каждая новость описывается следующими полями:\n","* **url** - адрес новости на сайте `lenta.ru`,\n","* **topic** - тема новости,\n","* **title** - заголовок новости,\n","* **text** - текст новости.\n","\n","Ответьте на следуюшие вопросы:\n","1. Сколько всего новостных текстов?\n","2. На какие темы встречаются новости?\n","3. Сколько новостных текстов в каждой теме?"]},{"cell_type":"markdown","metadata":{"id":"jBTuCxFKNe22"},"source":["**Задание 2.** Выполните предобработку новостных текстов в виде:\n","- приведение к нижнему регистру,\n","- удаление знаков пунктуации.\n","\n","**(!) Далее в лабораторной работе задания выполняются с полученными обработанными текстами**.\n","\n","Разделите датасет на обучающую и тестовую части в соотношении 80% к 20%. Выведите диаграммы, отражающие количество текстов по каждой теме в каждой из частей."]},{"cell_type":"markdown","metadata":{"id":"PK0zMLkjNe22"},"source":["**Задание 3.** Подсчитайте частоту встречаемости слов предобработанных новостных текстов `обучающей` части датафрейма. Какие слова употребляются наиболее часто вцелом в этих новостных текстах, а какие слова употребляются в этих же новостных текстах относительно тем (выведите топ-`50` слов для каждого случая)?\n","\n","Нахождение частот слов в новостных текстах датафрейма можно выполнять посредством инструмента `FreqDist` библиотеки `NLTK`.\n","\n","Например:\n","```\n","df['text'].apply(lambda x: nltk.FreqDist(nltk.word_tokenize(x)))\n","```"]},{"cell_type":"markdown","metadata":{"id":"kB6aTP1CNe23"},"source":["**Задание 4.** Составьте словари из текстов `обучающей` части датасетов наболее часто встречающихся слов, которые встречаются **только в одной из каждых тем**. Постройте диаграмму для топ-`50` этих слов для каждой темы (ось X - слова, ось Y - частоты встречаемости слов в новостных текстах)."]},{"cell_type":"markdown","metadata":{"id":"Qptkq3vdNe23"},"source":["**Задание 5.** Выполните классификацию новостных текстов из `тестовой` части датасета на основе `top-k слов` (`k` - как входной параметр) из словарей, построенных в задании `4` на основе `обучающей` части датасета. Оцените показатели `полнота` и `точность` классификации (относительно значения параметра `k`) при указании количества документов, для которых не получилось определить тему.\n","\n","Общий алгоритм классификации:\n","\n","- Для документа `x` считаем сколько встречается слов, из словаря каждой из тем.\n","- Выбираем тему для документа `x` с максимальным количеством слов\n","- Отдельно обрабатываем случаи, когда количество слов одинаковое или равно 0. Это случаи, когда не получилось определить тему документа."]},{"cell_type":"markdown","metadata":{"id":"7G45Gf3INe23"},"source":["**Задание 6.** Познакомьтесь с библиотекой Natasha для обработки текстов на русском языке, прочитав <a href=\"https://habr.com/ru/articles/516098/\">статью</a>."]},{"cell_type":"markdown","metadata":{"id":"ORckot5FNe23"},"source":["#### Импорт библиотек и создание объекта для работы с текстом\n","Импортируйте библиотеки для сегментации на предложения, морфологического и синтаксического анализа.\n","\n","```python\n","from natasha import(\n","    Segmenter,\n","    MorphVocab,\n","    NewsEmbedding,\n","    NewsMorphTagger,\n","    NewsSyntaxParser,\n","    Doc,\n",")\n","```\n","\n","Создайте объект из обрабатываемого текста `text`:\n","\n","```python\n","text_doc = Doc(text)\n","```"]},{"cell_type":"markdown","metadata":{"id":"Wv2SnFnKNe23"},"source":["#### Сегментация на предложения\n","Создайте объект, который будет выполнять сегментацию текста на предложения:\n","\n","```python\n","segmenter = Segmenter()\n","```\n","\n","С помощью сегментатора можно разбить текст на предложения и токены:\n","\n","```python\n","text_doc.segment(segmenter)\n","print(text_doc.tokens)\n","print(text_doc.sents)\n","```"]},{"cell_type":"markdown","metadata":{"id":"o0QJCWd5Ne23"},"source":["#### Морфологический анализ\n","\n","Инициализируйте словарь и морфологический анализатор:\n","```python\n","morph_vocab = MorphVocab()\n","morph_tagger = NewsMorphTagger(emb)\n","```\n","\n","Чтобы получить морфологическую разметку слова `word` воспользуйтесь:\n","\n","```python\n","morph_vocab.parse(word)\n","```\n","\n","Добавить морфологическую разметку к объекту обрабатываемого текста (Doc) можно как\n","\n","```python\n","text_doc.tag_morph(morph_tagger)\n","print(text_doc.tokens)\n","text_doc.sents[0].morph.print()\n","```\n","\n","Получить леммы текста можно через метод `lemmatize`:\n","\n","```python\n","for token in text_doc.tokens:\n","    token.lemmatize(morph_vocab)\n","{_.text: _.lemma for _ in text_doc.tokens}\n","```"]},{"cell_type":"markdown","metadata":{"id":"PE1lOP42Ne23"},"source":["**Задание 7.** Добавьте столбец в обучающую и тестовую часть датасета с обработанными текстами после лемматизации."]},{"cell_type":"markdown","metadata":{"id":"v_lrR-9zNe24"},"source":["**Задание 8.** Составьте словари на основе текстов `обучающей` части датасета по аналогии с **заданием 4.**, но с текстами, полученными после лемматзации."]},{"cell_type":"markdown","metadata":{"id":"UMaAd55sNe24"},"source":["**Задание 9.** Сделайте классификацию новостных текстов `тестовой` части датасета по аналогии с **заданием 5.**, но с текстами, полученными **после лемматзации**."]}],"metadata":{"kernelspec":{"display_name":"ta_env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.1"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}